{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on tutorial: Traffic sign classifier with Tensorflow\n",
    "\n",
    "## Preparation steps\n",
    "You can download this jupyter notebook with git from here:\n",
    "`git clone https://github.com/olesalscheider/traffic-sign-tutorial`\n",
    "\n",
    "Please follow these preparation steps before the hands-on tutorial so that you come with a prepared system:\n",
    "\n",
    "* Please install all required dependencies:\n",
    "  * Python 3\n",
    "  * Jupyter\n",
    "    * `pip3 install --upgrade jupyter`\n",
    "  * Pillow\n",
    "    * `pip3 install --upgrade pillow`\n",
    "  * urllib3\n",
    "    * `pip3 install --upgrade urllib3`\n",
    "  * numpy\n",
    "    * `pip3 install --upgrade numpy`\n",
    "  * Tensorflow\n",
    "    * `pip3 install --upgrade tensorflow` for the CPU variant\n",
    "    * `pip3 install --upgrade tensorflow-gpu` if you have a GPU with CUDA and CUDNN support\n",
    "    * More details on https://www.tensorflow.org/install/\n",
    "* Download and extract the traffic sign dataset (GTSRB). Execute the first cell with Python code the jupyter notebook to do so.\n",
    "\n",
    "## Prepare the dataset\n",
    "\n",
    "Let's start by splitting the data into a train and a test dataset. We store the filenames in two CSV files and use approximately 80% of the data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting data...\n",
      "Converting images and splitting datasets...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "DATA_URL = 'http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip'\n",
    "\n",
    "print('Downloading and extracting data...')\n",
    "with urllib.request.urlopen(DATA_URL) as response:\n",
    "    archive = response.read()\n",
    "    with zipfile.ZipFile(io.BytesIO(archive)) as zip_ref:\n",
    "        zip_ref.extractall(DATA_PATH)\n",
    "\n",
    "print('Converting images and splitting datasets...')\n",
    "train_file_path = os.path.join(DATA_PATH, 'train')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test')\n",
    "with open(train_file_path, 'w') as train_file, open(test_file_path, 'w') as test_file:\n",
    "    # Iterate over all image files in the training data\n",
    "    # directory and store the paths in the CSV files\n",
    "    for dirpath, dirnames, files in os.walk(DATA_PATH):\n",
    "        is_train_example = {}\n",
    "        for file in files:\n",
    "            if file.endswith('.ppm'):\n",
    "                # Convert ppm to png (Tensorflow cannot read ppm)\n",
    "                newfile = file.replace('ppm', 'png')\n",
    "                im = Image.open(os.path.join(dirpath, file))\n",
    "                im.save(os.path.join(dirpath, newfile))\n",
    "                im.close()\n",
    "\n",
    "                # The last directory name encodes the class\n",
    "                # of the training example.\n",
    "                _, label = os.path.split(dirpath)\n",
    "                \n",
    "                # Convert it to an integer (this strips the leading zeros).\n",
    "                label = int(label)\n",
    "\n",
    "                # There are multiple images of each sign.\n",
    "                # The number before the '_' gives the sign number.\n",
    "                # Make sure that different images of the same sign are\n",
    "                # only stored either in the training or the test set.\n",
    "                sign_no = int(file.split('_')[0])\n",
    "\n",
    "                # Generate the string that should be stored in the CSV file.\n",
    "                # It is the image path and the class label.\n",
    "                line = os.path.join(dirpath, newfile) + '\\t' + str(label) + '\\n'\n",
    "\n",
    "                # Store the line either in the training or test CSV file\n",
    "                if not sign_no in is_train_example.keys():\n",
    "                    # keep 80% of the data for training and 20% for testing.\n",
    "                    is_train_example[sign_no] = np.random.randint(0, 10) > 1\n",
    "                if is_train_example[sign_no]:\n",
    "                    train_file.writelines(line)\n",
    "                else:\n",
    "                    test_file.writelines(line)\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a data reader\n",
    "\n",
    "The data reader reads the CSV files for training and testing. These CSV files contain one example per line. This line contains the file name to the image file (png) and the class label (integer number betwenn 0 and 42).\n",
    "\n",
    "The data reader is implemented as a `tf.data.Dataset` for each dataset and a generic `tf.data.Iterator` to iterate over the elements in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "\n",
    "# Create a Tensorflow graph and add all operations to it from now on.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Define a function that takes a line from the CSV file\n",
    "    # and returns the decoded image and label\n",
    "    def read_data(line):\n",
    "        # Decode the line from the CSV file\n",
    "        path, label = tf.decode_csv(line, [[''], [0]], field_delim='\\t')\n",
    "        # Read the binary data from the image file\n",
    "        file = tf.read_file(path)\n",
    "        # Decode the image\n",
    "        image = tf.image.decode_png(file, 3)\n",
    "\n",
    "        # Resize the image to 48x48 pixels\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        image = tf.image.resize_bilinear(image, [48, 48])\n",
    "        image = tf.squeeze(image, axis=0)\n",
    "        image.set_shape([48, 48, 3])\n",
    "        return image, label\n",
    "\n",
    "    ## Create the training dataset\n",
    "    train_dataset = tf.data.TextLineDataset(os.path.join(DATA_PATH, 'train'))\n",
    "    # Shuffle the training dataset\n",
    "    train_dataset = train_dataset.shuffle(30000)\n",
    "    # Call the read_data function for each entry\n",
    "    train_dataset = train_dataset.map(read_data, 2)\n",
    "    # Repeat the dataset 2 times\n",
    "    train_dataset = train_dataset.repeat(2)\n",
    "    # Create batches with 32 training examples\n",
    "    train_dataset = train_dataset.batch(32)\n",
    "\n",
    "    ## Create the test dataset\n",
    "    test_dataset = tf.data.TextLineDataset(os.path.join(DATA_PATH, 'test'))\n",
    "    # Call the read_data function for each entry\n",
    "    test_dataset = test_dataset.map(read_data, 2)\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "\n",
    "    ## Create a generic iterator\n",
    "    iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "\n",
    "    ## Create initializer operations for the iterator.\n",
    "    ## These assign either the test of train dataset.\n",
    "    train_init_op = iterator.make_initializer(train_dataset)\n",
    "    test_init_op = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "First we define a class for one ResNet module. A ResNet module looks like this:\n",
    "\n",
    "![ResNet module](img/resnet_module.png)\n",
    "\n",
    "Variant 1 is used when the number of input channels equals the number of output channels.\n",
    "But if the number of channels is different, the tensors cannot be summed element-wise.\n",
    "In this case we have to use variant 2. Here, we add a 1x1 convolution in the skip connection. This convolution adjusts the number of channels so that both tensors can be summed element-wise.\n",
    "\n",
    "Let's implement this module as a `tf.keras.Model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGULARIZER_WEIGHT = 1e-5\n",
    "\n",
    "class ResnetModule(tf.keras.Model):\n",
    "    def __init__(self, name, num_output_channels):\n",
    "        super().__init__(name=name)\n",
    "        self.num_output_channels = num_output_channels\n",
    "\n",
    "    # The build function is called before using the\n",
    "    # model for the first time. When it is called, the\n",
    "    # input shapes are (partially) known and passed as\n",
    "    # parameter.\n",
    "    # We instantiate the sub-layers in this function.\n",
    "    def build(self, input_shapes):\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.num_output_channels,\n",
    "            (3, 3),\n",
    "            padding='same',\n",
    "            kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER_WEIGHT),\n",
    "            name='conv1')\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.num_output_channels,\n",
    "            (3, 3),\n",
    "            padding='same',\n",
    "            kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER_WEIGHT),\n",
    "            name='conv2')\n",
    "\n",
    "        self.conv3 = None\n",
    "        if input_shapes[-1] != self.num_output_channels:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(self.num_output_channels,\n",
    "                (1, 1),\n",
    "                kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER_WEIGHT),\n",
    "                name='conv3')\n",
    "\n",
    "    # The call function is called when the model is\n",
    "    # evaluated. We call the sub-layers and simple\n",
    "    # functions to perform the operations of the model.\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        x = self.bn1(x, training=True)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        if self.conv3:\n",
    "            y = self.conv3(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=True)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a simple model that consists of some ResNet modules. It will look like this:\n",
    "\n",
    "![Network](img/network.png)\n",
    "\n",
    "The first layer is a convolution with a 7x7 kernel, stride 2 and 32 output channels.\n",
    "This is followed by a batch normalization layer.\n",
    "Then three ResNet modules and three 2x2 maxpool layers follow in an alternating fashion. The ResNet Modules have 64, 128 and 256 channels respectively.\n",
    "The last layer is a fully-connected (dense) layer. It reduces the number of channels to the number of traffic sign classes in our dataset (43).\n",
    "\n",
    "Let's also implement this as a `tf.keras.Model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignModel(tf.keras.Model):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    # The build function is called before using the\n",
    "    # model for the first time. When it is called, the\n",
    "    # input shapes are (partially) known and passed as\n",
    "    # parameter.\n",
    "    # We instantiate the sub-layers in this function.\n",
    "    def build(self, input_shapes):\n",
    "        self.first_conv = tf.keras.layers.Conv2D(32,\n",
    "            (7, 7),\n",
    "            strides=(2, 2),\n",
    "            activation=tf.keras.activations.relu,\n",
    "            kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER_WEIGHT),\n",
    "            name='first_conv')\n",
    "\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.maxpool1 = tf.keras.layers.MaxPooling2D(2, 2)\n",
    "        self.maxpool2 = tf.keras.layers.MaxPooling2D(2, 2)\n",
    "        self.maxpool3 = tf.keras.layers.MaxPooling2D(2, 2)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        self.module1 = ResnetModule('rm1', 64)\n",
    "        self.module2 = ResnetModule('rm2', 128)\n",
    "        self.module3 = ResnetModule('rm3', 256)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(43) # We have 43 classes\n",
    "\n",
    "    # The call function is called when the model is\n",
    "    # evaluated. We call the sub-layers and simple\n",
    "    # functions to perform the operations of the model.\n",
    "    def call(self, image):\n",
    "        # Cast the image to float\n",
    "        x = tf.cast(image, tf.float32)\n",
    "        # normalize it to a range between -1 and 1\n",
    "        x = (x - tf.constant(128.0, tf.float32)) / tf.constant(128.0, tf.float32)\n",
    "\n",
    "        # Run the neural network layers on the image\n",
    "        x = self.first_conv(x)\n",
    "        x = self.bn1(x, training=True)\n",
    "        x = self.module1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.module2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.module3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the model\n",
    "\n",
    "Now that we have a data reader and defined the model, we can train it.\n",
    "\n",
    "We will instantiate the TrafficSignModel class, pass the data from the dataset iterator as input and get the predictions as output.\n",
    "\n",
    "From this and the ground truth, we can calculate the loss. Here we will use the cross-entropy loss.\n",
    "Then we instantiate the Adam optimizer to minimize the loss function by adjusting the weights of the model.\n",
    "\n",
    "Finally, we will initialize all variables and execute the optimizer in a training loop to get the trained network.\n",
    "We will then evaluate this trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the traffic light classifier. This might take a while...\n",
      "Step    0 - Accuracy: 0.0312, loss: 148.9601\n",
      "Step   20 - Accuracy: 0.2500, loss: 93.6495\n",
      "Step   40 - Accuracy: 0.3438, loss: 85.7958\n",
      "Step   60 - Accuracy: 0.3750, loss: 85.0194\n",
      "Step   80 - Accuracy: 0.3125, loss: 58.0994\n",
      "Step  100 - Accuracy: 0.5312, loss: 44.0348\n",
      "Step  120 - Accuracy: 0.7500, loss: 23.1573\n",
      "Step  140 - Accuracy: 0.7812, loss: 26.9473\n",
      "Step  160 - Accuracy: 0.6875, loss: 27.1270\n",
      "Step  180 - Accuracy: 0.7500, loss: 28.1763\n",
      "Step  200 - Accuracy: 0.9062, loss: 15.2979\n",
      "Step  220 - Accuracy: 0.8750, loss: 16.2155\n",
      "Step  240 - Accuracy: 0.8750, loss: 13.1626\n",
      "Step  260 - Accuracy: 0.9688, loss: 7.1028\n",
      "Step  280 - Accuracy: 1.0000, loss: 2.0630\n",
      "Step  300 - Accuracy: 1.0000, loss: 0.5348\n",
      "Step  320 - Accuracy: 0.9688, loss: 4.0895\n",
      "Step  340 - Accuracy: 0.9688, loss: 2.9327\n",
      "Step  360 - Accuracy: 1.0000, loss: 1.8904\n",
      "Step  380 - Accuracy: 1.0000, loss: 1.4692\n",
      "Step  400 - Accuracy: 0.9688, loss: 3.3526\n",
      "Step  420 - Accuracy: 0.9375, loss: 4.2099\n",
      "Step  440 - Accuracy: 0.9062, loss: 4.8813\n",
      "Step  460 - Accuracy: 0.9688, loss: 3.1992\n",
      "Step  480 - Accuracy: 1.0000, loss: 1.6386\n",
      "Step  500 - Accuracy: 1.0000, loss: 0.5600\n",
      "Step  520 - Accuracy: 1.0000, loss: 0.3012\n",
      "Step  540 - Accuracy: 1.0000, loss: 1.1091\n",
      "Step  560 - Accuracy: 0.9688, loss: 1.9976\n",
      "Step  580 - Accuracy: 1.0000, loss: 0.1070\n",
      "Step  600 - Accuracy: 1.0000, loss: 0.1671\n",
      "Step  620 - Accuracy: 1.0000, loss: 0.5147\n",
      "Step  640 - Accuracy: 0.9375, loss: 3.6102\n",
      "Step  660 - Accuracy: 1.0000, loss: 0.4060\n",
      "Step  680 - Accuracy: 1.0000, loss: 0.9350\n",
      "Step  700 - Accuracy: 0.9688, loss: 8.2853\n",
      "Step  720 - Accuracy: 1.0000, loss: 1.4621\n",
      "Step  740 - Accuracy: 1.0000, loss: 0.2208\n",
      "Step  760 - Accuracy: 1.0000, loss: 1.0059\n",
      "Step  780 - Accuracy: 1.0000, loss: 0.1700\n",
      "Step  800 - Accuracy: 1.0000, loss: 1.1785\n",
      "Step  820 - Accuracy: 1.0000, loss: 0.7793\n",
      "Step  840 - Accuracy: 1.0000, loss: 0.3373\n",
      "Step  860 - Accuracy: 1.0000, loss: 0.2390\n",
      "Step  880 - Accuracy: 0.9375, loss: 3.3449\n",
      "Step  900 - Accuracy: 1.0000, loss: 0.7565\n",
      "Step  920 - Accuracy: 1.0000, loss: 0.0210\n",
      "Step  940 - Accuracy: 0.9688, loss: 4.9008\n",
      "Step  960 - Accuracy: 1.0000, loss: 0.1463\n",
      "Step  980 - Accuracy: 1.0000, loss: 0.0607\n",
      "Step 1000 - Accuracy: 1.0000, loss: 0.0740\n",
      "Step 1020 - Accuracy: 1.0000, loss: 0.0442\n",
      "Step 1040 - Accuracy: 1.0000, loss: 0.1524\n",
      "Step 1060 - Accuracy: 1.0000, loss: 0.0683\n",
      "Step 1080 - Accuracy: 1.0000, loss: 0.1263\n",
      "Step 1100 - Accuracy: 1.0000, loss: 0.1742\n",
      "Step 1120 - Accuracy: 1.0000, loss: 0.0314\n",
      "Step 1140 - Accuracy: 0.9688, loss: 1.8055\n",
      "Step 1160 - Accuracy: 1.0000, loss: 0.0396\n",
      "Step 1180 - Accuracy: 1.0000, loss: 0.1178\n",
      "Step 1200 - Accuracy: 1.0000, loss: 0.0311\n",
      "Step 1220 - Accuracy: 1.0000, loss: 0.0886\n",
      "Step 1240 - Accuracy: 1.0000, loss: 0.1393\n",
      "Step 1260 - Accuracy: 1.0000, loss: 0.2553\n",
      "Step 1280 - Accuracy: 1.0000, loss: 0.0242\n",
      "Step 1300 - Accuracy: 1.0000, loss: 0.3715\n",
      "Step 1320 - Accuracy: 1.0000, loss: 0.4466\n",
      "Step 1340 - Accuracy: 1.0000, loss: 0.0370\n",
      "Step 1360 - Accuracy: 1.0000, loss: 0.0290\n",
      "Step 1380 - Accuracy: 1.0000, loss: 0.2716\n",
      "Step 1400 - Accuracy: 1.0000, loss: 0.1237\n",
      "Step 1420 - Accuracy: 1.0000, loss: 0.1216\n",
      "Step 1440 - Accuracy: 1.0000, loss: 0.0190\n",
      "Step 1460 - Accuracy: 1.0000, loss: 0.0277\n",
      "Step 1480 - Accuracy: 1.0000, loss: 0.0347\n",
      "Step 1500 - Accuracy: 1.0000, loss: 0.0268\n",
      "Step 1520 - Accuracy: 1.0000, loss: 0.0718\n",
      "Step 1540 - Accuracy: 1.0000, loss: 0.0398\n",
      "Step 1560 - Accuracy: 1.0000, loss: 0.0731\n",
      "Step 1580 - Accuracy: 1.0000, loss: 0.0347\n",
      "Step 1600 - Accuracy: 1.0000, loss: 0.0423\n",
      "Step 1620 - Accuracy: 1.0000, loss: 0.0345\n",
      "Step 1640 - Accuracy: 1.0000, loss: 0.1267\n",
      "Step 1660 - Accuracy: 1.0000, loss: 0.0427\n",
      "Step 1680 - Accuracy: 1.0000, loss: 0.0905\n",
      "Step 1700 - Accuracy: 1.0000, loss: 0.0324\n",
      "Step 1720 - Accuracy: 0.9688, loss: 2.9714\n",
      "Step 1740 - Accuracy: 1.0000, loss: 0.0528\n",
      "Step 1760 - Accuracy: 1.0000, loss: 0.2967\n",
      "Step 1780 - Accuracy: 1.0000, loss: 0.0383\n",
      "Step 1800 - Accuracy: 1.0000, loss: 0.2033\n",
      "Step 1820 - Accuracy: 1.0000, loss: 0.0694\n",
      "Step 1840 - Accuracy: 1.0000, loss: 0.0677\n",
      "Step 1860 - Accuracy: 1.0000, loss: 0.0412\n",
      "Step 1880 - Accuracy: 1.0000, loss: 0.1126\n",
      "Step 1900 - Accuracy: 1.0000, loss: 0.0912\n",
      "Step 1920 - Accuracy: 1.0000, loss: 0.3391\n",
      "Step 1940 - Accuracy: 1.0000, loss: 0.1193\n",
      "Step 1960 - Accuracy: 1.0000, loss: 0.6236\n",
      "Evaluate the classifier. This might take a while...\n",
      "Mean accuracy on the test dataset: 0.9582\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    session = tf.Session()\n",
    "\n",
    "    # Instantiate the model we want to train\n",
    "    net = TrafficSignModel('net')\n",
    "    images, labels = iterator.get_next()\n",
    "    logits = net(images)\n",
    "\n",
    "    # Define the loss\n",
    "    loss_op = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "    loss_op += tf.reduce_sum(net.losses) # Add regularizer losses\n",
    "\n",
    "    # Define an OP to calculate the accuracy\n",
    "    correct_prediction = tf.equal(tf.cast(tf.argmax(logits, 1), tf.int32), labels)\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # Define the learning rate schedule and the optimizer OP.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(1e-3, global_step, 500, 0.5)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_op, global_step=global_step)\n",
    "    train_op = tf.group(train_op, net.updates) # Add batch norm updates\n",
    "\n",
    "    # Initialize the model variables (randomly).\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Train the traffic light classifier. This might take a while...')\n",
    "    # Initialize the dataset iterator for training.\n",
    "    session.run(train_init_op)\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            _, accuracy, loss = session.run([train_op, accuracy_op, loss_op])\n",
    "            if i % 20 == 0:\n",
    "                print('Step %4i - Accuracy: %.4f, loss: %.4f' % (i, accuracy, loss))\n",
    "            i += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break # We finished!\n",
    "    \n",
    "    print('Evaluate the classifier. This might take a while...')\n",
    "    # Initialize the dataset iterator for training.\n",
    "    session.run(test_init_op)\n",
    "    i = 0\n",
    "    total_accuracy = 0.0\n",
    "    while True:\n",
    "        try:\n",
    "            accuracy = session.run(accuracy_op)\n",
    "            total_accuracy += accuracy\n",
    "            i += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break # We finished!\n",
    "    print('Mean accuracy on the test dataset: %.4f' % (total_accuracy / i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
